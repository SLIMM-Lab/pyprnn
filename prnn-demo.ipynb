{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d5fe4f-675c-4708-9267-1549d4cbff6a",
   "metadata": {},
   "source": [
    "# Physically Recurrent Neural Networks - Demo notebook\n",
    "\n",
    "This notebook demonstrates how to train a PRNN (or an RNN), save and load checkpoints, and evaluate model performance after training.\n",
    "\n",
    "## How to use this resource\n",
    "\n",
    "After loading packages and downloading checkpoints and datasets with the first block, all other code blocks are self-contained. They perform a range of different tasks involving training, validating and comparing PRNNs against each other and against variational RNNs. Running the notebook from top to bottom is therefore not necessary. Feel free to use these blocks as the starting point of more involved applications of PRNNs.\n",
    "\n",
    "## Load packages, get datasets and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0c6d9-ed79-4572-b702-4b84d2ed6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "# If using Google Colab, uncomment the lines below\n",
    "# Be aware that performance will take a hit when using Colab\n",
    "    \n",
    "# !pip install ipympl==0.9.3\n",
    "# !pip install matplotlib==3.5.2\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()\n",
    "# %cd '/content/drive/MyDrive/your_folder'\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from utils import Trainer\n",
    "from utils import StressStrainDataset\n",
    "\n",
    "from prnn import PRNN\n",
    "from rnn  import GRU\n",
    "from rnn  import LSTM\n",
    "from rnn  import ELBOLoss\n",
    "\n",
    "from visualizer import PlotNN\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# Download and unzip datasets and checkpoints, if necessary.\n",
    "# The files should take in total about 18mb of space.\n",
    "# Comment these lines if that is not desirable\n",
    "if not os.path.isdir('datasets'):\n",
    "    print('Downloading and unzipping datasets...')\n",
    "    urlretrieve('https://surfdrive.surf.nl/files/index.php/s/OcSDq0zNqkVbvIO/download', 'datasets.zip')\n",
    "    zip_file = zipfile.ZipFile('datasets.zip')\n",
    "    zip_file.extractall('.')\n",
    "    \n",
    "if not os.path.isdir('trained_models'):\n",
    "    print('Downloading and unzipping model checkpoints...')\n",
    "    urlretrieve('https://surfdrive.surf.nl/files/index.php/s/XyIWSNUKp47jnrY/download', 'checkpoints.zip')\n",
    "    zip_file = zipfile.ZipFile('checkpoints.zip')\n",
    "    zip_file.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38603a26-19f6-4e26-a9b5-6d93d5b52640",
   "metadata": {},
   "source": [
    "## Example code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d1194-70ad-4653-972e-cf841e2beab8",
   "metadata": {},
   "source": [
    "### Train an RNN on 80 GP paths, for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59170be-fd28-40f4-b185-724fc2baae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Data is loaded from a text file in the format [eps_xx eps_yy gam_xy sig_xx sig_yy tau_xy]\n",
    "# Strain paths are separated by blank lines. All paths have 60 time steps\n",
    "dataset = StressStrainDataset('datasets/gpCurves.data', [0,1,2], [3,4,5], seq_length=60)\n",
    "\n",
    "# Split dataset into 80 curves for training and 20 for validation\n",
    "# manual_seed=42 is also used for pre-trained models\n",
    "tset, vset = torch.utils.data.random_split(dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "tloader = torch.utils.data.DataLoader(tset, batch_size=4, shuffle=True)\n",
    "vloader = torch.utils.data.DataLoader(vset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Initialize network\n",
    "gru = GRU(n_features=3, n_outputs=3, n_latents=64, dropout=True)\n",
    "\n",
    "# Train network for very small number of epochs \n",
    "# Set learning rate dangerously high to get fast training for demonstration purposes\n",
    "trainer = Trainer(gru, loss=ELBOLoss(gru.dropout), optimizer=torch.optim.Adam(gru.parameters(), lr=1e-2))\n",
    "trainer.train(tloader, vloader, epochs=200, patience=10, interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1105a-5a3f-49a4-8860-7484ddf06b1d",
   "metadata": {},
   "source": [
    "### Train a PRNN model on 18 simple paths, for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb9d00-ef6c-4ea9-978a-22c10c61f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = StressStrainDataset('datasets/canonical.data', [0,1,2], [3,4,5], seq_length=60)\n",
    "\n",
    "tloader = torch.utils.data.DataLoader(dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "prnn = PRNN(n_features=3, n_outputs=3, n_matpts=2)\n",
    "\n",
    "# Set learning rate dangerously high to get fast training for demonstration purposes\n",
    "trainer = Trainer(prnn, optimizer=torch.optim.Adam(prnn.parameters(), lr=1e-1))\n",
    "\n",
    "# Use training set for validation (effectively disabling early stopping)\n",
    "trainer.train(tloader, tloader, epochs=20, patience=10)\n",
    "\n",
    "# Save the partially trained model\n",
    "trainer.save('trained_models/my_first_prnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e60fc0-b746-4d42-9383-7c35c5e54fed",
   "metadata": {},
   "source": [
    "### Load a pre-trained PRNN and use it to evaluate 20 GP curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aea255-5922-45fc-81db-cdb2b4c529c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = StressStrainDataset('datasets/gpCurves.data', [0,1,2], [3,4,5], seq_length=60)\n",
    "\n",
    "_, vset = torch.utils.data.random_split(dataset, [0.80, 0.20], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "vloader = torch.utils.data.DataLoader(vset, batch_size=1, shuffle=False) # Set batch_size=1 so error is printed for each strain path\n",
    "\n",
    "prnn_pre = PRNN(n_features=3, n_outputs=3, n_matpts=2)\n",
    "trainer_pre = Trainer(prnn_pre)\n",
    "\n",
    "trainer_pre.load('trained_models/prnn_gp_80_0.pth') # Trained on 80 GP curves for 10000 epochs\n",
    "\n",
    "trainer_pre.eval(vloader, loss=torch.nn.L1Loss()) # Absolute error (L1Loss) for better interpretability of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b121e7-987f-4ba8-aa1c-fd85585c507b",
   "metadata": {},
   "source": [
    "### Compare two different models curve by curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa58e38-3ea0-4e95-b3fc-86ca3e30828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = StressStrainDataset('datasets/gpCurves.data', [0,1,2], [3,4,5], seq_length=60)\n",
    "\n",
    "_, vset = torch.utils.data.random_split(dataset, [0.80, 0.20], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "vloader = torch.utils.data.DataLoader(vset, batch_size=1, shuffle=False)\n",
    "\n",
    "prnn = PRNN(n_features=3, n_outputs=3, n_matpts=2)\n",
    "\n",
    "gru  = GRU(n_features=3, n_outputs=3, n_latents=64, dropout=True)\n",
    "\n",
    "trainer1 = Trainer(prnn)\n",
    "trainer1.load('trained_models/prnn_gp_5_0.pth') # Trained on 5 GP curves for 10000 epochs\n",
    "\n",
    "trainer2 = Trainer(gru)\n",
    "trainer2.load('trained_models/gru_gp_5_0.pth') # Trained on 5 GP curves for 10000 epochs\n",
    "\n",
    "plot = PlotNN(vloader, [prnn, gru], ['PRNN (5 paths)', 'GRU (5 paths)']) # Try it out for more than 2 models!\n",
    "plot.add_buttons('previous','random','next')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b840a5-8890-40f1-9d73-e28a330e0e14",
   "metadata": {},
   "source": [
    "### Check how prediction accuracy increases with more data (learning curve) with pretrained PRNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56ef29-60db-4ef7-b10c-36f71fb35ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "test_dataset = StressStrainDataset('datasets/gpCurves.data', [0,1,2], [3,4,5], seq_length=60)\n",
    "\n",
    "_, vset = torch.utils.data.random_split(test_dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "vloader = torch.utils.data.DataLoader(vset, batch_size=20, shuffle=False) # Set batch_size=20 for efficiency\n",
    "\n",
    "prnn = PRNN(n_features=3, n_outputs=3, n_matpts=2)\n",
    "\n",
    "trainer = Trainer(prnn)\n",
    "networks = glob.glob('trained_models/prnn_gp*.pth')\n",
    "\n",
    "size = []\n",
    "loss = []\n",
    "\n",
    "for fn in networks:\n",
    "    print('testing network from checkpoint: ' + fn)\n",
    "    trainer.load(fn)\n",
    "    size.append(float(fn.split('_')[-2]))\n",
    "    loss.append(trainer.eval(vloader, loss=torch.nn.L1Loss(),verbose=False))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(size,loss,'.')\n",
    "plt.title('PRNN learning curve (trained and tested on GP paths)')\n",
    "plt.ylabel('Loss [MPa]')\n",
    "plt.xlabel('Training dataset size [strain paths]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d637d7-3d2a-42d1-95b1-87f123b3642d",
   "metadata": {},
   "source": [
    "### Plot a GRU learning curve on the same dataset, for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee080bd-5810-4d69-b322-c32ddfe816cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = StressStrainDataset('datasets/gpCurves.data', [0,1,2], [3,4,5], seq_length=60)\n",
    "\n",
    "_, vset = torch.utils.data.random_split(test_dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "vloader = torch.utils.data.DataLoader(vset, batch_size=20, shuffle=False) # Set batch_size=20 for efficiency\n",
    "\n",
    "gru = GRU(n_features=3, n_outputs=3, n_latents=64, dropout=True)\n",
    "\n",
    "trainer = Trainer(gru)\n",
    "networks = glob.glob('trained_models/gru_gp*.pth')\n",
    "\n",
    "size = []\n",
    "loss = []\n",
    "\n",
    "for fn in networks:\n",
    "    print('testing network from checkpoint: ' + fn)\n",
    "    trainer.load(fn)\n",
    "    size.append(float(fn.split('_')[-2]))\n",
    "    loss.append(trainer.eval(vloader, loss=torch.nn.L1Loss(), verbose=False))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(size,loss,'.')\n",
    "plt.title('GRU learning curve (trained and tested on GP paths)')\n",
    "plt.ylabel('Loss [MPa]')\n",
    "plt.xlabel('Training dataset size [strain paths]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854f9eb-e6f4-42a4-9ca3-2e18ad6f1a8e",
   "metadata": {},
   "source": [
    "### Train a hundred PRNNs from scratch and plot a learning curve\n",
    "\n",
    "Please note this block can take a long time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0703c7c-13ee-4f06-ba2a-d67a4d242b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = StressStrainDataset('datasets/gpCurves.data', [0,1,2], [3,4,5], seq_length=60)\n",
    "\n",
    "Tset, vset = torch.utils.data.random_split(dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "vloader = torch.utils.data.DataLoader(vset, batch_size=1, shuffle=False)\n",
    "\n",
    "ncurves = list(range(1,11))\n",
    "nmodels = 10\n",
    "nepochs = 5000\n",
    "path    = 'lc_prnn_gp'\n",
    "\n",
    "# Train 10 models for each dataset size.\n",
    "# Datasets are uniformly sampled from a pool of 80 curves, i.e\n",
    "# each of the 10 models has a different training dataset.\n",
    "# Training and evaluation output suppressed by the 'verbose' flag\n",
    "\n",
    "if os.path.isdir(path):\n",
    "    shutil.rmtree(path)\n",
    "os.mkdir(path)\n",
    "\n",
    "for ncurve in ncurves:\n",
    "    for nmodel in range(nmodels):\n",
    "        tset, xset = torch.utils.data.random_split(Tset, [float(ncurve/80), float(1-ncurve/80)], generator=torch.Generator().manual_seed(ncurve + nmodel))\n",
    "\n",
    "        tloader = torch.utils.data.DataLoader(tset, batch_size=5, shuffle=True)\n",
    "\n",
    "        print('\\nTraining with',ncurve,'curve(s). Network',nmodel+1,'of',nmodels)\n",
    "\n",
    "        prnn = PRNN(n_features=3, n_outputs=3, n_matpts=2)\n",
    "        trainer = Trainer(prnn,optimizer=torch.optim.Adam(prnn.parameters(),lr=1.e-2))\n",
    "        trainer.train(tloader, vloader, epochs=nepochs, patience=200, interval=10, verbose=False)\n",
    "        trainer.save(os.path.join(path,'prnn'+'_gp_'+str(ncurve)+'_'+str(nmodel)+'.pth'))\n",
    "\n",
    "# Plot the learning curve\n",
    "\n",
    "prnn = PRNN(n_features=3, n_outputs=3, n_matpts=2)\n",
    "\n",
    "trainer = Trainer(prnn)\n",
    "networks = glob.glob(path+'/prnn_gp*.pth')\n",
    "\n",
    "size = []\n",
    "loss = []\n",
    "\n",
    "for fn in networks:\n",
    "    print('\\nTesting network from checkpoint: ' + fn)\n",
    "    trainer.load(fn)\n",
    "    size.append(float(fn.split('_')[-2]))\n",
    "    loss.append(trainer.eval(vloader, loss=torch.nn.L1Loss(),verbose=False))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(size,loss,'.')\n",
    "plt.ylabel('Loss [MPa]')\n",
    "plt.xlabel('n curves')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
